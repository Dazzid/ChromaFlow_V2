{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer, TrainerConfig\n",
    "from mingpt_utils import set_seed\n",
    "from model import GPT, GPTConfig\n",
    "import torch\n",
    "from utils import *\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from mingpt_utils import sample\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:  2\n",
      "torch version: 2.2.0a0+81ea7a4\n",
      "cudnn version: 8907\n",
      "cuda version: 12.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Available devices: \", torch.cuda.device_count())\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"cudnn version:\", torch.backends.cudnn.version())\n",
    "print(\"cuda version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1024\n",
    "id = 0\n",
    "tokens = np.load('../data/formatted/tokens.npy', allow_pickle=True)\n",
    "train = np.load('../data/shuffled/dataset_train.npy', allow_pickle=True)\n",
    "test = np.load('../data/shuffled/dataset_test.npy', allow_pickle=True)\n",
    "midi_train = np.load('../data/shuffled/midi_train.npy', allow_pickle=True)\n",
    "midi_test = np.load('../data/shuffled/midi_test.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad tokens: 16773876, Percentage: 37.86%\n"
     ]
    }
   ],
   "source": [
    "pad_tokens = 0\n",
    "elements = 0\n",
    "for song in train:\n",
    "    for e in song:\n",
    "        if e == '<pad>':\n",
    "            pad_tokens += 1\n",
    "        elements += 1\n",
    "\n",
    "percentage = pad_tokens / elements * 100\n",
    "print(f\"Pad tokens: {pad_tokens}, Percentage: {percentage:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert midi into dtype int\n",
    "midi_train = midi_train.astype(int)\n",
    "midi_test = midi_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43272, 1024) (4800, 1024) (43272, 1024, 8) (4800, 1024, 8)\n",
      "data has 43272 pieces, 198 unique tokens.\n",
      "data has 4800 pieces, 198 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape, midi_train.shape, midi_test.shape)\n",
    "\n",
    "dataset = TokenDatasetMidi(train, midi_train,  max_length, tokens)\n",
    "validation = TokenDatasetMidi(test, midi_test, max_length, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 0, '/': 1, '0.3997395833333333': 2, '0.4440104166666667': 3, '0.5': 4, '0.5703125': 5, '0.6666666666666666': 6, '0.75': 7, '0.7994791666666666': 8, '0.8880208333333334': 9, '1.0': 10, '1.1419270833333333': 11, '1.3333333333333333': 12, '1.5': 13, '1.5989583333333333': 14, '1.7135416666666667': 15, '128 Feel': 16, '2.0': 17, '2.25': 18, '2.3997395833333335': 19, '2.6666666666666665': 20, '3.0': 21, '4.0': 22, ':|': 23, '<end>': 24, '<pad>': 25, '<start>': 26, '<style>': 27, 'A': 28, 'A major': 29, 'A minor': 30, 'A#': 31, 'A##': 32, 'Ab': 33, 'Ab major': 34, 'Ab minor': 35, 'Abb': 36, 'Afoxé': 37, 'Afro': 38, 'B': 39, 'B major': 40, 'B minor': 41, 'B#': 42, 'B##': 43, 'Baião': 44, 'Ballad': 45, 'Bb': 46, 'Bb major': 47, 'Bb minor': 48, 'Bbb': 49, 'Blues': 50, 'Bolero': 51, 'Bolero-Cha': 52, 'Bossa': 53, 'C': 54, 'C major': 55, 'C minor': 56, 'C#': 57, 'C##': 58, 'Calypso': 59, 'Cb': 60, 'Cbb': 61, 'Cha Cha': 62, 'Chacarera': 63, 'Choro': 64, 'Country Ballad': 65, 'D': 66, 'D major': 67, 'D minor': 68, 'D#': 69, 'D##': 70, 'Db': 71, 'Db major': 72, 'Db minor': 73, 'Dbb': 74, 'Disco': 75, 'Dreamlike': 76, 'E': 77, 'E major': 78, 'E minor': 79, 'E#': 80, 'E##': 81, 'Eb': 82, 'Eb major': 83, 'Eb minor': 84, 'Ebb': 85, 'Even 16ths': 86, 'Even 8ths': 87, 'F': 88, 'F major': 89, 'F minor': 90, 'F#': 91, 'F##': 92, 'Fb': 93, 'Fbb': 94, 'Folk': 95, 'Form_A': 96, 'Form_B': 97, 'Form_C': 98, 'Form_Coda': 99, 'Form_D': 100, 'Form_Segno': 101, 'Form_intro': 102, 'Form_verse': 103, 'Forró': 104, 'Foxtrot': 105, 'Frevo': 106, 'Funk': 107, 'G': 108, 'G major': 109, 'G minor': 110, 'G#': 111, 'G##': 112, 'Gary Aprile': 113, 'Gb': 114, 'Gb major': 115, 'Gb minor': 116, 'Gbb': 117, 'Gospel': 118, 'Gospel Ballad': 119, 'Gypsy Waltz': 120, 'Hymn': 121, 'Jazz': 122, 'Latin': 123, 'Mambo': 124, 'March': 125, 'Marchinha': 126, 'Maxixe': 127, 'Med Up Latin': 128, 'Medium Ballad': 129, 'Medium Country': 130, 'Medium Shuffle': 131, 'Medium Slow': 132, 'Medium Up': 133, 'Medium Waltz': 134, 'Merengue': 135, 'Moderate Latin': 136, 'Montuno': 137, 'Musical': 138, 'N.C.': 139, 'Pop': 140, 'Power Ballad': 141, 'Reggae': 142, 'Repeat_0': 143, 'Repeat_1': 144, 'Repeat_2': 145, 'Repeat_3': 146, 'RnB': 147, 'Rock': 148, 'Salsa': 149, 'Samba': 150, 'Shuffle': 151, 'Slow Ballad': 152, 'Slow Shuffle': 153, 'Slowly': 154, 'Son': 155, 'Soul': 156, 'Tango': 157, 'Tonality': 158, 'Up Tempo': 159, 'Up Waltz (One Feel)': 160, 'Waltz': 161, 'add #11': 162, 'add #5': 163, 'add #7': 164, 'add #9': 165, 'add 11': 166, 'add 13': 167, 'add 2': 168, 'add 7': 169, 'add 9': 170, 'add b13': 171, 'add b6': 172, 'add b9': 173, 'alter #11': 174, 'alter #5': 175, 'alter #9': 176, 'alter b5': 177, 'alter b9': 178, 'aug': 179, 'b||': 180, 'dom7': 181, 'e||': 182, 'm': 183, 'm6': 184, 'm7': 185, 'maj': 186, 'maj6': 187, 'maj7': 188, 'major-13th': 189, 'o': 190, 'o7': 191, 'o_maj7': 192, 'power': 193, 'sus4': 194, 'sus7': 195, '|': 196, '|:': 197}\n"
     ]
    }
   ],
   "source": [
    "stoi = { tk:i for i,tk in enumerate(tokens) }\n",
    "itos = { i:tk for i,tk in enumerate(tokens) }\n",
    "\n",
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:05:31 - ERROR - wandb.jupyter -   Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdazzid\u001b[0m (\u001b[33mmusic_gpt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/src/wandb/run-20240418_090532-qxewvhgx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/music_gpt/music_gpt_new_voicing/runs/qxewvhgx' target=\"_blank\">snowy-night-26</a></strong> to <a href='https://wandb.ai/music_gpt/music_gpt_new_voicing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/music_gpt/music_gpt_new_voicing' target=\"_blank\">https://wandb.ai/music_gpt/music_gpt_new_voicing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/music_gpt/music_gpt_new_voicing/runs/qxewvhgx' target=\"_blank\">https://wandb.ai/music_gpt/music_gpt_new_voicing/runs/qxewvhgx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/music_gpt/music_gpt_new_voicing/runs/qxewvhgx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0897dbb460>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "#wandb.login()\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"music_gpt_new_voicing\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"architecture\": \"Transformer - minGPT\",\n",
    "    \"dataset\": \"chords from iRealPro\",\n",
    "    \"epochs\": 270,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# # Example command to list processes using GPU (this won't run here due to sandbox restrictions)\n",
    "# output = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "# print(output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:06:35 - INFO - model -   number of parameters: 1.283021e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/model_epochs->270_heads->4_embd->512_batch->128_new_midi_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:06:36 - INFO - model -   number of parameters: 1.283021e+07\n",
      "epoch 1 iter 338: train loss 2.08555. lr 3.000000e-05: 100%|██████████| 339/339 [02:42<00:00,  2.09it/s]\n",
      "04/18/2024 09:09:19 - INFO - trainer -   epoch train loss: 2.879668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.8796677329195637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:09:27 - INFO - trainer -   test loss: 1.909220\n",
      "epoch 2 iter 338: train loss 1.57121. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:12:08 - INFO - trainer -   epoch train loss: 1.865582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.8655815859459846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:12:14 - INFO - trainer -   test loss: 1.608145\n",
      "epoch 3 iter 338: train loss 1.38269. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:14:55 - INFO - trainer -   epoch train loss: 1.589002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5890019235357773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:15:02 - INFO - trainer -   test loss: 1.547545\n",
      "epoch 4 iter 338: train loss 1.29671. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:17:43 - INFO - trainer -   epoch train loss: 1.475286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.475286076554155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:17:50 - INFO - trainer -   test loss: 1.564558\n",
      "epoch 5 iter 338: train loss 1.21842. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 09:20:32 - INFO - trainer -   epoch train loss: 1.404776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.4047755115503406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:20:38 - INFO - trainer -   test loss: 1.447742\n",
      "epoch 6 iter 338: train loss 1.12696. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:23:19 - INFO - trainer -   epoch train loss: 1.334487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.33448720998117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:23:26 - INFO - trainer -   test loss: 1.381283\n",
      "epoch 7 iter 338: train loss 1.09398. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:26:07 - INFO - trainer -   epoch train loss: 1.283754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.2837537643128791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:26:14 - INFO - trainer -   test loss: 1.313069\n",
      "epoch 8 iter 338: train loss 1.06398. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:28:55 - INFO - trainer -   epoch train loss: 1.254079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.2540786515998277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:29:02 - INFO - trainer -   test loss: 1.273768\n",
      "epoch 9 iter 338: train loss 1.01430. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:31:43 - INFO - trainer -   epoch train loss: 1.220625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.220624970475481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:31:50 - INFO - trainer -   test loss: 1.226836\n",
      "epoch 10 iter 338: train loss 0.97980. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:34:31 - INFO - trainer -   epoch train loss: 1.188096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1880959564253994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:34:38 - INFO - trainer -   test loss: 1.192800\n",
      "epoch 11 iter 338: train loss 0.96818. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:37:18 - INFO - trainer -   epoch train loss: 1.161498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1614975874754532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:37:25 - INFO - trainer -   test loss: 1.176975\n",
      "epoch 12 iter 338: train loss 0.94697. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:40:06 - INFO - trainer -   epoch train loss: 1.137500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1374997639023097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:40:13 - INFO - trainer -   test loss: 1.133290\n",
      "epoch 13 iter 338: train loss 0.92461. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:42:54 - INFO - trainer -   epoch train loss: 1.112322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1123219062093437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:43:01 - INFO - trainer -   test loss: 1.101093\n",
      "epoch 14 iter 338: train loss 0.90416. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:45:42 - INFO - trainer -   epoch train loss: 1.084624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0846240875643616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:45:49 - INFO - trainer -   test loss: 1.064536\n",
      "epoch 15 iter 338: train loss 0.87931. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:48:29 - INFO - trainer -   epoch train loss: 1.054814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0548140633422716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:48:36 - INFO - trainer -   test loss: 1.014189\n",
      "epoch 16 iter 338: train loss 0.84083. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:51:17 - INFO - trainer -   epoch train loss: 1.021155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0211549716009856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:51:24 - INFO - trainer -   test loss: 0.985637\n",
      "epoch 17 iter 338: train loss 0.81470. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:54:05 - INFO - trainer -   epoch train loss: 0.987435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.9874346245706609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:54:12 - INFO - trainer -   test loss: 0.949778\n",
      "epoch 18 iter 338: train loss 0.77435. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:56:53 - INFO - trainer -   epoch train loss: 0.956869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.9568686363971339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:56:59 - INFO - trainer -   test loss: 0.923403\n",
      "epoch 19 iter 338: train loss 0.73971. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 09:59:40 - INFO - trainer -   epoch train loss: 0.928984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.9289836582884324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 09:59:47 - INFO - trainer -   test loss: 0.897391\n",
      "epoch 20 iter 338: train loss 0.72011. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:02:28 - INFO - trainer -   epoch train loss: 0.907758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.9077580551833881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:02:35 - INFO - trainer -   test loss: 0.883291\n",
      "epoch 21 iter 338: train loss 0.70147. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:05:16 - INFO - trainer -   epoch train loss: 0.891558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.8915582842531458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:05:23 - INFO - trainer -   test loss: 0.868341\n",
      "epoch 22 iter 338: train loss 0.68608. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:08:03 - INFO - trainer -   epoch train loss: 0.877522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.87752181678395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:08:10 - INFO - trainer -   test loss: 0.856308\n",
      "epoch 23 iter 338: train loss 0.67815. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:10:51 - INFO - trainer -   epoch train loss: 0.864637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.8646371600198887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:10:58 - INFO - trainer -   test loss: 0.844781\n",
      "epoch 24 iter 338: train loss 0.66295. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:13:39 - INFO - trainer -   epoch train loss: 0.852824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.8528237356900465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:13:46 - INFO - trainer -   test loss: 0.833302\n",
      "epoch 25 iter 338: train loss 0.64959. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:16:26 - INFO - trainer -   epoch train loss: 0.841823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.8418226094372505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:16:33 - INFO - trainer -   test loss: 0.823002\n",
      "epoch 26 iter 338: train loss 0.64992. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:19:14 - INFO - trainer -   epoch train loss: 0.831713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.8317127575916526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:19:21 - INFO - trainer -   test loss: 0.811982\n",
      "epoch 27 iter 338: train loss 0.62836. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:22:02 - INFO - trainer -   epoch train loss: 0.821319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.8213191603840628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:22:09 - INFO - trainer -   test loss: 0.801548\n",
      "epoch 28 iter 338: train loss 0.62301. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:24:50 - INFO - trainer -   epoch train loss: 0.808871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.8088706276409745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:24:57 - INFO - trainer -   test loss: 0.782126\n",
      "epoch 29 iter 338: train loss 0.60373. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:27:37 - INFO - trainer -   epoch train loss: 0.792324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.7923235615446153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:27:45 - INFO - trainer -   test loss: 0.758362\n",
      "epoch 30 iter 338: train loss 0.58896. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:30:26 - INFO - trainer -   epoch train loss: 0.768044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.7680435764402767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:30:33 - INFO - trainer -   test loss: 0.722696\n",
      "epoch 31 iter 338: train loss 0.57357. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 10:33:14 - INFO - trainer -   epoch train loss: 0.742604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.7426037107948709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:33:21 - INFO - trainer -   test loss: 0.693898\n",
      "epoch 32 iter 338: train loss 0.54728. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 10:36:02 - INFO - trainer -   epoch train loss: 0.719349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.7193491402628851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:36:09 - INFO - trainer -   test loss: 0.658933\n",
      "epoch 33 iter 338: train loss 0.52544. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 10:38:51 - INFO - trainer -   epoch train loss: 0.682668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.682668452945079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:38:58 - INFO - trainer -   test loss: 0.572786\n",
      "epoch 34 iter 338: train loss 0.46346. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 10:41:40 - INFO - trainer -   epoch train loss: 0.612400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6123997351940402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:41:46 - INFO - trainer -   test loss: 0.481804\n",
      "epoch 35 iter 338: train loss 0.41990. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 10:44:28 - INFO - trainer -   epoch train loss: 0.542275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5422751679357174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:44:35 - INFO - trainer -   test loss: 0.411316\n",
      "epoch 36 iter 338: train loss 0.39238. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 10:47:16 - INFO - trainer -   epoch train loss: 0.484219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.48421948436087214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:47:23 - INFO - trainer -   test loss: 0.371565\n",
      "epoch 37 iter 338: train loss 0.35892. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 10:50:04 - INFO - trainer -   epoch train loss: 0.442897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.442896536229986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:50:11 - INFO - trainer -   test loss: 0.345337\n",
      "epoch 38 iter 338: train loss 0.33275. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 10:52:53 - INFO - trainer -   epoch train loss: 0.410174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4101738410185924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:53:00 - INFO - trainer -   test loss: 0.324895\n",
      "epoch 39 iter 338: train loss 0.30004. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.11it/s]\n",
      "04/18/2024 10:55:41 - INFO - trainer -   epoch train loss: 0.384688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.38468845219387066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:55:48 - INFO - trainer -   test loss: 0.311090\n",
      "epoch 40 iter 338: train loss 0.27569. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 10:58:29 - INFO - trainer -   epoch train loss: 0.364630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3646297242964967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 10:58:36 - INFO - trainer -   test loss: 0.300343\n",
      "epoch 41 iter 338: train loss 0.26213. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:01:17 - INFO - trainer -   epoch train loss: 0.348676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3486758859987456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:01:24 - INFO - trainer -   test loss: 0.291915\n",
      "epoch 42 iter 338: train loss 0.25776. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 11:04:05 - INFO - trainer -   epoch train loss: 0.335141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.33514139240821905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:04:12 - INFO - trainer -   test loss: 0.285656\n",
      "epoch 43 iter 338: train loss 0.24923. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:06:53 - INFO - trainer -   epoch train loss: 0.323667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3236671628589827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:07:00 - INFO - trainer -   test loss: 0.279908\n",
      "epoch 44 iter 338: train loss 0.23648. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 11:09:42 - INFO - trainer -   epoch train loss: 0.313615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.31361494813345175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:09:49 - INFO - trainer -   test loss: 0.275066\n",
      "epoch 45 iter 338: train loss 0.23528. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:12:30 - INFO - trainer -   epoch train loss: 0.304722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3047218357039764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:12:37 - INFO - trainer -   test loss: 0.271548\n",
      "epoch 46 iter 338: train loss 0.21756. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 11:15:18 - INFO - trainer -   epoch train loss: 0.296976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2969760425762441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:15:25 - INFO - trainer -   test loss: 0.267980\n",
      "epoch 47 iter 338: train loss 0.22044. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 11:18:07 - INFO - trainer -   epoch train loss: 0.290460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.29045981898420326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:18:14 - INFO - trainer -   test loss: 0.264823\n",
      "epoch 48 iter 338: train loss 0.20910. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 11:20:55 - INFO - trainer -   epoch train loss: 0.284422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.28442211506289367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:21:02 - INFO - trainer -   test loss: 0.262037\n",
      "epoch 49 iter 338: train loss 0.19887. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:23:43 - INFO - trainer -   epoch train loss: 0.279073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2790732948125991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:23:50 - INFO - trainer -   test loss: 0.259306\n",
      "epoch 50 iter 338: train loss 0.19654. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 11:26:32 - INFO - trainer -   epoch train loss: 0.274003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.27400327972782046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:26:39 - INFO - trainer -   test loss: 0.257474\n",
      "epoch 51 iter 338: train loss 0.19746. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.11it/s]\n",
      "04/18/2024 11:29:20 - INFO - trainer -   epoch train loss: 0.269659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2696589649075252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:29:27 - INFO - trainer -   test loss: 0.254204\n",
      "epoch 52 iter 338: train loss 0.18821. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:32:08 - INFO - trainer -   epoch train loss: 0.265301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2653013121413622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:32:15 - INFO - trainer -   test loss: 0.252178\n",
      "epoch 53 iter 338: train loss 0.18606. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:34:56 - INFO - trainer -   epoch train loss: 0.261432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.26143168734941513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:35:03 - INFO - trainer -   test loss: 0.249086\n",
      "epoch 54 iter 338: train loss 0.18060. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 11:37:45 - INFO - trainer -   epoch train loss: 0.257887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.257886881058195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:37:51 - INFO - trainer -   test loss: 0.247663\n",
      "epoch 55 iter 338: train loss 0.18334. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:40:32 - INFO - trainer -   epoch train loss: 0.254337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.25433734178015616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:40:39 - INFO - trainer -   test loss: 0.246301\n",
      "epoch 56 iter 338: train loss 0.17094. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:43:20 - INFO - trainer -   epoch train loss: 0.251150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2511495347395759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:43:27 - INFO - trainer -   test loss: 0.244198\n",
      "epoch 57 iter 338: train loss 0.16909. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:46:09 - INFO - trainer -   epoch train loss: 0.248042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.24804177401164287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:46:16 - INFO - trainer -   test loss: 0.244433\n",
      "epoch 58 iter 338: train loss 0.16872. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:48:57 - INFO - trainer -   epoch train loss: 0.245238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.24523822154443173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:49:04 - INFO - trainer -   test loss: 0.241539\n",
      "epoch 59 iter 338: train loss 0.16935. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:51:45 - INFO - trainer -   epoch train loss: 0.242345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.24234510505445586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:51:52 - INFO - trainer -   test loss: 0.241101\n",
      "epoch 60 iter 338: train loss 0.16382. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 11:54:33 - INFO - trainer -   epoch train loss: 0.239720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2397202569386952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:54:40 - INFO - trainer -   test loss: 0.239250\n",
      "epoch 61 iter 338: train loss 0.15606. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.11it/s]\n",
      "04/18/2024 11:57:21 - INFO - trainer -   epoch train loss: 0.237136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.23713559514477542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 11:57:28 - INFO - trainer -   test loss: 0.238726\n",
      "epoch 62 iter 338: train loss 0.15835. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:00:09 - INFO - trainer -   epoch train loss: 0.234610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2346095016836065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:00:16 - INFO - trainer -   test loss: 0.237304\n",
      "epoch 63 iter 338: train loss 0.15313. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 12:02:58 - INFO - trainer -   epoch train loss: 0.232198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.23219795903097565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:03:05 - INFO - trainer -   test loss: 0.236708\n",
      "epoch 64 iter 338: train loss 0.15122. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:05:46 - INFO - trainer -   epoch train loss: 0.229752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.22975180221166583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:05:53 - INFO - trainer -   test loss: 0.236328\n",
      "epoch 65 iter 338: train loss 0.15068. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:08:34 - INFO - trainer -   epoch train loss: 0.227491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.22749064744046305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:08:41 - INFO - trainer -   test loss: 0.235219\n",
      "epoch 66 iter 338: train loss 0.14667. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:11:22 - INFO - trainer -   epoch train loss: 0.225186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2251862329719341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:11:28 - INFO - trainer -   test loss: 0.234559\n",
      "epoch 67 iter 338: train loss 0.14115. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 12:14:10 - INFO - trainer -   epoch train loss: 0.223106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2231062101667258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:14:17 - INFO - trainer -   test loss: 0.233396\n",
      "epoch 68 iter 338: train loss 0.14516. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:16:58 - INFO - trainer -   epoch train loss: 0.220932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.22093218595756542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:17:05 - INFO - trainer -   test loss: 0.233212\n",
      "epoch 69 iter 338: train loss 0.13671. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:19:46 - INFO - trainer -   epoch train loss: 0.218656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.21865648514753247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:19:53 - INFO - trainer -   test loss: 0.232990\n",
      "epoch 70 iter 338: train loss 0.13541. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:22:34 - INFO - trainer -   epoch train loss: 0.216663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2166628715387136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:22:41 - INFO - trainer -   test loss: 0.232660\n",
      "epoch 71 iter 338: train loss 0.13412. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 12:25:23 - INFO - trainer -   epoch train loss: 0.214530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.21452979664359473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:25:29 - INFO - trainer -   test loss: 0.232430\n",
      "epoch 72 iter 338: train loss 0.13504. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:28:11 - INFO - trainer -   epoch train loss: 0.212571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.21257133087401545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:28:18 - INFO - trainer -   test loss: 0.231351\n",
      "epoch 73 iter 338: train loss 0.13203. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:30:59 - INFO - trainer -   epoch train loss: 0.210503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.21050318271185445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:31:06 - INFO - trainer -   test loss: 0.231708\n",
      "epoch 74 iter 338: train loss 0.12828. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 12:33:47 - INFO - trainer -   epoch train loss: 0.208540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.20854031292386463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:33:54 - INFO - trainer -   test loss: 0.231332\n",
      "epoch 75 iter 338: train loss 0.12538. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 12:36:35 - INFO - trainer -   epoch train loss: 0.206599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.20659915931456913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:36:42 - INFO - trainer -   test loss: 0.231070\n",
      "epoch 76 iter 338: train loss 0.12100. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:39:23 - INFO - trainer -   epoch train loss: 0.204646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.20464576558817102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:39:30 - INFO - trainer -   test loss: 0.231840\n",
      "epoch 77 iter 338: train loss 0.12311. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:42:11 - INFO - trainer -   epoch train loss: 0.202638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.2026377609301809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:42:18 - INFO - trainer -   test loss: 0.231184\n",
      "epoch 78 iter 338: train loss 0.11791. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:44:59 - INFO - trainer -   epoch train loss: 0.200685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.20068538347176745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:45:06 - INFO - trainer -   test loss: 0.231445\n",
      "epoch 79 iter 338: train loss 0.11778. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:47:47 - INFO - trainer -   epoch train loss: 0.198781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1987807805427408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:47:54 - INFO - trainer -   test loss: 0.231601\n",
      "epoch 80 iter 338: train loss 0.11472. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:50:35 - INFO - trainer -   epoch train loss: 0.196897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.19689681521647096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:50:41 - INFO - trainer -   test loss: 0.231980\n",
      "epoch 81 iter 338: train loss 0.11746. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:53:22 - INFO - trainer -   epoch train loss: 0.195037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.19503685221032055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:53:29 - INFO - trainer -   test loss: 0.232289\n",
      "epoch 82 iter 338: train loss 0.11708. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:56:10 - INFO - trainer -   epoch train loss: 0.193204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1932035354034739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:56:17 - INFO - trainer -   test loss: 0.233088\n",
      "epoch 83 iter 338: train loss 0.10857. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 12:58:58 - INFO - trainer -   epoch train loss: 0.191341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.19134069768200934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 12:59:05 - INFO - trainer -   test loss: 0.232947\n",
      "epoch 84 iter 338: train loss 0.10948. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:01:46 - INFO - trainer -   epoch train loss: 0.189301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.18930127610147526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:01:53 - INFO - trainer -   test loss: 0.233881\n",
      "epoch 85 iter 338: train loss 0.10278. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:04:34 - INFO - trainer -   epoch train loss: 0.187581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.18758055099607568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:04:41 - INFO - trainer -   test loss: 0.234061\n",
      "epoch 86 iter 338: train loss 0.10855. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:07:22 - INFO - trainer -   epoch train loss: 0.185725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.18572521143782456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:07:28 - INFO - trainer -   test loss: 0.234528\n",
      "epoch 87 iter 338: train loss 0.10096. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:10:10 - INFO - trainer -   epoch train loss: 0.183909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.18390912224145767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:10:17 - INFO - trainer -   test loss: 0.234986\n",
      "epoch 88 iter 338: train loss 0.10321. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:12:58 - INFO - trainer -   epoch train loss: 0.182078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.18207765045331292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:13:05 - INFO - trainer -   test loss: 0.235767\n",
      "epoch 89 iter 338: train loss 0.09847. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:15:45 - INFO - trainer -   epoch train loss: 0.180185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.18018544689480182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:15:52 - INFO - trainer -   test loss: 0.236710\n",
      "epoch 90 iter 338: train loss 0.09711. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:18:33 - INFO - trainer -   epoch train loss: 0.178350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.17835009955199418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:18:40 - INFO - trainer -   test loss: 0.238691\n",
      "epoch 91 iter 338: train loss 0.09841. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:21:21 - INFO - trainer -   epoch train loss: 0.176623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1766226905505214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:21:28 - INFO - trainer -   test loss: 0.238122\n",
      "epoch 92 iter 338: train loss 0.09604. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.11it/s]\n",
      "04/18/2024 13:24:10 - INFO - trainer -   epoch train loss: 0.174805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1748046876538468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:24:17 - INFO - trainer -   test loss: 0.239304\n",
      "epoch 93 iter 338: train loss 0.09308. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:26:58 - INFO - trainer -   epoch train loss: 0.173095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.17309484520932567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:27:05 - INFO - trainer -   test loss: 0.240776\n",
      "epoch 94 iter 338: train loss 0.09109. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:29:45 - INFO - trainer -   epoch train loss: 0.171305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1713054867400884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:29:52 - INFO - trainer -   test loss: 0.241263\n",
      "epoch 95 iter 338: train loss 0.09282. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:32:33 - INFO - trainer -   epoch train loss: 0.169452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.16945195918941217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:32:40 - INFO - trainer -   test loss: 0.241127\n",
      "epoch 96 iter 338: train loss 0.08830. lr 3.000000e-05: 100%|██████████| 339/339 [02:41<00:00,  2.10it/s]\n",
      "04/18/2024 13:35:22 - INFO - trainer -   epoch train loss: 0.167844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.16784417176492797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:35:29 - INFO - trainer -   test loss: 0.242320\n",
      "epoch 97 iter 338: train loss 0.08867. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:38:10 - INFO - trainer -   epoch train loss: 0.166065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.16606513300916087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:38:17 - INFO - trainer -   test loss: 0.243296\n",
      "epoch 98 iter 338: train loss 0.08518. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:40:58 - INFO - trainer -   epoch train loss: 0.164277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.16427688830282133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:41:04 - INFO - trainer -   test loss: 0.245290\n",
      "epoch 99 iter 338: train loss 0.08550. lr 3.000000e-05: 100%|██████████| 339/339 [02:40<00:00,  2.11it/s]\n",
      "04/18/2024 13:43:46 - INFO - trainer -   epoch train loss: 0.162673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.16267312159844205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/18/2024 13:43:52 - INFO - trainer -   test loss: 0.245850\n",
      "epoch 100 iter 251: train loss 0.15759. lr 3.000000e-05:  74%|███████▍  | 252/339 [02:03<00:41,  2.10it/s]Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 233, in run\n",
      "    self._record_writer.write(data)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 766, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 160, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 164, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "OSError: [Errno 28] No space left on device\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n",
      "    self._hm.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/handler.py\", line 866, in finish\n",
      "    logger.info(\"shutting down handler\")\n",
      "Message: 'shutting down handler'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n",
      "    self._hm.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/handler.py\", line 868, in finish\n",
      "    self._system_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/system_monitor.py\", line 203, in finish\n",
      "    logger.info(\"Stopping system monitor\")\n",
      "Message: 'Stopping system monitor'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/system_monitor.py\", line 179, in _start\n",
      "    logger.debug(\"Finished system metrics aggregation loop\")\n",
      "Message: 'Finished system metrics aggregation loop'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n",
      "    self._hm.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/handler.py\", line 868, in finish\n",
      "    self._system_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n",
      "    asset.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/cpu.py\", line 163, in finish\n",
      "    self.metrics_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
      "    logger.info(f\"Joined {thread_name} monitor\")\n",
      "Message: 'Joined cpu monitor'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/system_monitor.py\", line 183, in _start\n",
      "    logger.debug(\"Publishing last batch of metrics\")\n",
      "Message: 'Publishing last batch of metrics'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n",
      "    self._hm.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/handler.py\", line 868, in finish\n",
      "    self._system_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n",
      "    asset.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/disk.py\", line 210, in finish\n",
      "    self.metrics_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
      "    logger.info(f\"Joined {thread_name} monitor\")\n",
      "Message: 'Joined disk monitor'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n",
      "    self._hm.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/handler.py\", line 868, in finish\n",
      "    self._system_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n",
      "    asset.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/gpu.py\", line 388, in finish\n",
      "    self.metrics_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
      "    logger.info(f\"Joined {thread_name} monitor\")\n",
      "Message: 'Joined gpu monitor'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n",
      "    self._hm.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/handler.py\", line 868, in finish\n",
      "    self._system_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n",
      "    asset.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/memory.py\", line 152, in finish\n",
      "    self.metrics_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
      "    logger.info(f\"Joined {thread_name} monitor\")\n",
      "Message: 'Joined memory monitor'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n",
      "    self._hm.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/handler.py\", line 868, in finish\n",
      "    self._system_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n",
      "    asset.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/network.py\", line 96, in finish\n",
      "    self.metrics_monitor.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n",
      "    logger.info(f\"Joined {thread_name} monitor\")\n",
      "Message: 'Joined network monitor'\n",
      "Arguments: ()\n",
      "epoch 100 iter 253: train loss 0.15337. lr 3.000000e-05:  75%|███████▍  | 254/339 [02:04<00:40,  2.09it/s]--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/sender.py\", line 1546, in finish\n",
      "    logger.info(\"shutting down sender\")\n",
      "Message: 'shutting down sender'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/service/streams.py\", line 49, in run\n",
      "    self._target(**self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 174, in wandb_internal\n",
      "    logger.error(f\"Thread {thread.name}:\", exc_info=exc_info)\n",
      "Message: 'Thread SenderThread:'\n",
      "Arguments: ()\n",
      "Thread SenderThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n",
      "    self._finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n",
      "    self._sm.finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/sender.py\", line 1549, in finish\n",
      "    self._output_raw_finish()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/sender.py\", line 1199, in _output_raw_finish\n",
      "    self._output_raw_flush(stream)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/sender.py\", line 1246, in _output_raw_flush\n",
      "    self._output_raw_file.write(data.encode(\"utf-8\"))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/filesystem.py\", line 128, in write\n",
      "    super().write(b\"\\n\".join(ret) + b\"\\n\")\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/filesystem.py\", line 95, in write\n",
      "    self.f.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "wandb: ERROR Internal wandb error: file data was not synced\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 255, in _read_packet_bytes\n",
      "    data = self._sock.recv(self._bufsize)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router_sock.py\", line 27, in _read_message\n",
      "    resp = self._sock_client.read_server_response(timeout=1)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 285, in read_server_response\n",
      "    data = self._read_packet_bytes(timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 259, in _read_packet_bytes\n",
      "    raise SockClientClosedError\n",
      "wandb.sdk.lib.sock_client.SockClientClosedError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n",
      "    msg = self._read_message()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router_sock.py\", line 29, in _read_message\n",
      "    raise MessageRouterClosedError\n",
      "wandb.sdk.interface.router.MessageRouterClosedError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/router.py\", line 77, in message_loop\n",
      "    logger.warning(\"message_loop has been closed\")\n",
      "Message: 'message_loop has been closed'\n",
      "Arguments: ()\n",
      "epoch 100 iter 261: train loss 0.16126. lr 3.000000e-05:  77%|███████▋  | 262/339 [02:08<00:36,  2.11it/s]Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 286, in check_stop_status\n",
      "    self._loop_check_status(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
      "    local_handle = request()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 840, in deliver_stop_status\n",
      "    return self._deliver_stop_status(status)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 494, in _deliver_stop_status\n",
      "    return self._deliver_record(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "    interface._publish(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "epoch 100 iter 261: train loss 0.16126. lr 3.000000e-05:  77%|███████▋  | 262/339 [2:44:15<48:16, 37.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../runs/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(session_model, dataset, validation, tconf, writer)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m save_model(MODEL_NAME, session_model)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# [optional] finish the wandb run, necessary in notebooks\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/src/trainer.py:181\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# counter used for learning rate decay\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[0;32m--> 181\u001b[0m     \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m         test_loss \u001b[38;5;241m=\u001b[39m run_epoch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/src/trainer.py:152\u001b[0m, in \u001b[0;36mTrainer.train.<locals>.run_epoch\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m    149\u001b[0m             lr \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;66;03m# report progress\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummaryWriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatchLoss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m iter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. lr \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124me\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_train:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py:391\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[1;32m    386\u001b[0m     scalar_value \u001b[38;5;241m=\u001b[39m workspace\u001b[38;5;241m.\u001b[39mFetchBlob(scalar_value)\n\u001b[1;32m    388\u001b[0m summary \u001b[38;5;241m=\u001b[39m scalar(\n\u001b[1;32m    389\u001b[0m     tag, scalar_value, new_style\u001b[38;5;241m=\u001b[39mnew_style, double_precision\u001b[38;5;241m=\u001b[39mdouble_precision\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_file_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalltime\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py:112\u001b[0m, in \u001b[0;36mFileWriter.add_summary\u001b[0;34m(self, summary, global_step, walltime)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Adds a `Summary` protocol buffer to the event file.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03mThis method wraps the provided summary in an `Event` protocol buffer\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mand adds it to the event file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    walltime (from time.time()) seconds after epoch\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m event \u001b[38;5;241m=\u001b[39m event_pb2\u001b[38;5;241m.\u001b[39mEvent(summary\u001b[38;5;241m=\u001b[39msummary)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalltime\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py:97\u001b[0m, in \u001b[0;36mFileWriter.add_event\u001b[0;34m(self, event, step, walltime)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# Make sure step is converted from numpy or other formats\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# since protobuf might not convert depending on version\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     event\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(step)\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py:113\u001b[0m, in \u001b[0;36mEventFileWriter.add_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, event_pb2\u001b[38;5;241m.\u001b[39mEvent):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an event_pb2.Event proto, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(event)\n\u001b[1;32m    112\u001b[0m     )\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py:166\u001b[0m, in \u001b[0;36m_AsyncWriter.write\u001b[0;34m(self, bytestring)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriter is closed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_byte_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytestring\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/queue.py:140\u001b[0m, in \u001b[0;36mQueue.put\u001b[0;34m(self, item, block, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxsize:\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f08cb3597e0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f0896b716c0, execution_count=11 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7f0896b717e0, raw_cell=\"epochs = 270\n",
      "embedding = 512\n",
      "heads = 4\n",
      "layers = 4\n",
      "..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64616c6d617a7a6f5f6368726f6d61666c6f77227d@ssh-remote%2B130.237.3.110/workspace/src/run.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py:433\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py:682\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py:357\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epochs = 270\n",
    "embedding = 512\n",
    "heads = 4\n",
    "layers = 4\n",
    "batch_size = 128\n",
    "learning_rate = 3e-5\n",
    "num_workers = 4\n",
    "midi_vocab = 128\n",
    "token_size = len(tokens)\n",
    "\n",
    "mconf = GPTConfig(len(tokens), dataset.block_size, midi_vocab, n_layer=layers, n_head=heads, n_embd=embedding)\n",
    "session_model = GPT(mconf)\n",
    "MODEL_NAME = \"../models/model_\"+ \"epochs->\" + str(epochs) + \"_heads->\" + str(heads) + \"_embd->\" + str(embedding) + \"_batch->\" + str(batch_size) + \"_new_midi_embeddings\"\n",
    "print(MODEL_NAME)\n",
    "\n",
    "session_model = load_model(MODEL_NAME, session_model)\n",
    "\n",
    "if (session_model == None):\n",
    "    #mconf = GPTConfig(len(tokens), dataset.block_size, n_layer=layers, n_head=heads, n_embd=embbedings)\n",
    "    session_model = GPT(mconf)\n",
    "    tconf = TrainerConfig(max_epochs=epochs, \n",
    "                          batch_size=batch_size, \n",
    "                          learning_rate=learning_rate, \n",
    "                          num_workers=num_workers\n",
    "                          )\n",
    "    writer = SummaryWriter(log_dir='../runs/'+'logs') \n",
    "    trainer = Trainer(session_model, dataset, validation, tconf, writer)\n",
    "    trainer.train()\n",
    "    save_model(MODEL_NAME, session_model)\n",
    "    # [optional] finish the wandb run, necessary in notebooks\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
