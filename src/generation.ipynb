{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GPT, GPTConfig\n",
    "import torch\n",
    "from utils import *\n",
    "import importlib\n",
    "\n",
    "from mingpt_utils import set_seed\n",
    "from mingpt_utils import sample_new, sample\n",
    "\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43272, 1024) (43272, 1024, 8)\n"
     ]
    }
   ],
   "source": [
    "tokens = np.load('../data/formatted/tokens.npy', allow_pickle=True)\n",
    "train = np.load('../data/shuffled/dataset_train.npy', allow_pickle=True)\n",
    "midi_train = np.load('../data/shuffled/midi_train.npy', allow_pickle=True)\n",
    "print(train.shape, midi_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 43272 pieces, 198 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "block_size = 1024\n",
    "dataset = TokenDatasetMidi(train, midi_train, block_size, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/27/2024 10:01:34 - INFO - model -   number of parameters: 3.269632e+06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded ../models/model_epochs->270_heads->4_embd->256_batch->128_new_midi_embeddings\n"
     ]
    }
   ],
   "source": [
    "epochs = 270\n",
    "embedding = 256\n",
    "heads = 4\n",
    "layers = 4\n",
    "batch_size = 128\n",
    "learning_rate = 3e-5\n",
    "num_workers = 4\n",
    "midi_vocab = 128\n",
    "token_size = len(tokens)\n",
    "\n",
    "mconf = GPTConfig(token_size, block_size, midi_vocab, n_layer=layers, n_head=heads, n_embd=embedding)\n",
    "session_model = GPT(mconf)\n",
    "\n",
    "MODEL_NAME = \"../models/model_\"+ \"epochs->\" + str(epochs) + \"_heads->\" + str(heads) + \"_embd->\" + str(embedding) + \"_batch->\" + str(batch_size) + \"_new_midi_embeddings\"\n",
    "\n",
    "session_model = load_model(MODEL_NAME, session_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import formats as fmt\n",
    "import voicing as vc\n",
    "voicing = vc.Voicing()\n",
    "\n",
    "def generateSample(context, duration, style, tonality, session_model, dataset, split = True, temperature=1.0, sample=True, top_k=None, top_p=0.99):\n",
    "    if split: \n",
    "        data, _ = fmt.getArrayOfElementsInChord(context, duration)\n",
    "        print(data)\n",
    "        data = ['<style>'] + [style] + ['Tonality'] + [tonality] + ['<start>'] + ['|'] + data\n",
    "    else:\n",
    "        data = context\n",
    "    \n",
    "    midi, _ = voicing.get_midi(data)\n",
    "    # for d, m in zip(data, midi):\n",
    "    #     print(d, m)\n",
    "\n",
    "    i = 0\n",
    "    while ( i < 200):    \n",
    "        x = torch.tensor([dataset.stoi[s] for s in data], dtype=torch.long)[None,...].to('cuda')\n",
    "        m = torch.tensor(midi, dtype=torch.long)[None,...].to('cuda')\n",
    "        \n",
    "        #print(x.shape, m.shape)\n",
    "        y = sample_new(session_model, x, m, 1, temperature=temperature, sample=sample, top_k=top_k, top_p=top_p)[0]\n",
    "        \n",
    "        data = [dataset.itos[int(i)] for i in y if dataset.itos[int(i)]]\n",
    "        \n",
    "        if len(data) > 2:\n",
    "            if data[-1] == data[-2]:\n",
    "                print(\"Duplicated element: \", data[-1], data[-2])\n",
    "                data = data[:-1]\n",
    "                \n",
    "        if data[-2] == '.' and data[-1] not in voicing.durations:\n",
    "            print(\"Durations are not correct: \", data[-1], data[-2])\n",
    "            data = data[:-2]\n",
    "            \n",
    "        if data[-2] in voicing.durations and data[-1] not in voicing.all_notes:\n",
    "            print(\"Note is not correct: \", data[-1], data[-2])\n",
    "            data = data[:-2]\n",
    "            \n",
    "        #print(data)\n",
    "        midi, status = voicing.get_midi(data)\n",
    "        if status == False:\n",
    "            #erase the last element\n",
    "            print(\"Error creating the MIDI format\")\n",
    "            break\n",
    "        i+=1 \n",
    "\n",
    "    #myChords = convertChordsFromOutput(data)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '4.0', 'F', 'maj7', '.', '4.0', 'F', 'maj7', '.', '4.0', 'Bb', 'maj7']\n",
      "['<style>', 'Pop', 'Tonality', 'F major', '<start>', '|', '.', '4.0', 'F', 'maj7', '.', '4.0', 'F', 'maj7', '.', '4.0', 'Bb', 'maj7', '|', '.', '4.0', 'Bb', 'maj7', '|', '.', '2.0', 'F', 'maj7', '.', '2.0', 'Bb', 'dom7', 'Form_A', '|', '.', '4.0', 'A', 'm', 'add 11', '|', '.', '4.0', 'D', 'dom7', 'add 11', '|', '.', '2.0', 'G', 'm7', 'add 9', '.', '2.0', 'D', 'dom7', 'add b9', '|', '.', '2.0', 'G', 'm7', 'add 9', '.', '1.0', 'D', 'm7', '/', 'C', '.', '1.0', 'G', 'dom7', '|', '.', '2.0', 'G', 'm7', '.', '2.0', 'D', 'dom7', 'add b9', '|', '.', '2.0', 'G', 'm7', 'add 9', '.', '1.0', 'D', 'm7', '/', 'C', '.', '1.0', 'G', 'dom7', '|', '.', '2.0', 'G', 'm7', '.', '2.0', 'D', 'dom7', 'add b9', '|', '.', '2.0', 'G', 'm7', 'add 9', '.', '1.0', 'D', 'm7', '/', 'C', '.', '1.0', 'G', 'dom7', 'add 9', '|', '.', '2.0', 'G', 'm7', '.', '2.0', 'D', 'dom7', 'add b9', '|', '.', '2.0', 'G', 'm7', 'add 9', '.', '1.0', 'D', 'm7', '/', 'C', '.', '1.0', 'G', 'dom7', '|', '.', '2.0', 'G', 'm7', '.', '2.0', 'D', 'dom7', 'add b9', '|', '.', '4.0', 'G', 'm7', '|', '.', '4.0', 'E', 'dom7', 'add 9', 'add #11', '|', '.', '4.0', 'C', 'maj7', 'add 9', '|', '.', '4.0', 'A', 'm', 'add 11', '|', '.', '4.0', 'G', 'm7', 'add 9', '|', '.', '4.0', 'C', 'maj', 'add 9', 'add #11', 'Form_B', '|', '.', '4.0', 'G', 'm7', '|', '.', '2.0', 'C', 'sus4', '.', '2.0', 'C', 'maj', '|', '.', '2.0', 'F', 'maj']\n",
      "\n",
      "<style> Pop Tonality F major <start> | . 4.0 F maj7 . 4.0 F maj7 . 4.0 Bb maj7 | . \n",
      "4.0 Bb maj7 | . 2.0 F maj7 . 2.0 Bb dom7 Form_A | . 4.0 A m add 11 | \n",
      ". 4.0 D dom7 add 11 | . 2.0 G m7 add 9 . 2.0 D dom7 add b9 | . 2.0 G \n",
      "m7 add 9 . 1.0 D m7 / C . 1.0 G dom7 | . 2.0 G m7 . 2.0 D \n",
      "dom7 add b9 | . 2.0 G m7 add 9 . 1.0 D m7 / C . 1.0 G dom7 | . \n",
      "2.0 G m7 . 2.0 D dom7 add b9 | . 2.0 G m7 add 9 . 1.0 D m7 / C \n",
      ". 1.0 G dom7 add 9 | . 2.0 G m7 . 2.0 D dom7 add b9 | . 2.0 G m7 \n",
      "add 9 . 1.0 D m7 / C . 1.0 G dom7 | . 2.0 G m7 . 2.0 D dom7 \n",
      "add b9 | . 4.0 G m7 | . 4.0 E dom7 add 9 add #11 | . 4.0 C maj7 add 9 | \n",
      ". 4.0 A m add 11 | . 4.0 G m7 add 9 | . 4.0 C maj add 9 add #11 Form_B | \n",
      ". 4.0 G m7 | . 2.0 C sus4 . 2.0 C maj | . 2.0 F maj "
     ]
    }
   ],
   "source": [
    "context = ['Fmaj7', 'Fmaj7', 'Bbmaj7']\n",
    "\n",
    "divide = True\n",
    "duration = np.full(len(context), 4.0, dtype=float)\n",
    "myStyle = 'Pop'\n",
    "tonality = 'F major'\n",
    "data = generateSample(context, duration, myStyle, tonality, session_model, dataset, divide, temperature=1.2, sample=True, top_k=None, top_p=0.933)\n",
    "\n",
    "c = 0\n",
    "for e in data:\n",
    "    if c % 20 == 0: \n",
    "        print()\n",
    "    print(e, end=' ')\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song: 111311_27_3_2024_generated_Pop.mid\n",
      "file: 111311_27_3_2024_generated_Pop.txt\n",
      "MIDI file created! \n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(vc)\n",
    "voicing = vc.Voicing()\n",
    "\n",
    "myStyle = data[1]\n",
    "midi, _ = voicing.convert_chords_to_voicing(data)\n",
    "\n",
    "voicing.export_to_midi(midi, \"generated_\"+myStyle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
