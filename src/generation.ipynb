{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model import GPT, GPTConfig\n",
    "import torch\n",
    "from utils import *\n",
    "import importlib\n",
    "\n",
    "from mingpt_utils import set_seed\n",
    "from mingpt_utils import sample_new, sample\n",
    "\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/formatted/tokens.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/formatted/tokens.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/shuffled/dataset_train.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m midi_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/shuffled/midi_train.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/formatted/tokens.npy'"
     ]
    }
   ],
   "source": [
    "tokens = np.load('../data/formatted/tokens.npy', allow_pickle=True)\n",
    "train = np.load('../data/shuffled/dataset_train.npy', allow_pickle=True)\n",
    "midi_train = np.load('../data/shuffled/midi_train.npy', allow_pickle=True)\n",
    "print(train.shape, midi_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 43272 pieces, 198 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "block_size = 1024\n",
    "dataset = TokenDatasetMidi(train, midi_train, block_size, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/13/2024 13:44:30 - INFO - model -   number of parameters: 1.283021e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded ../models/model_epochs->100_heads->4_embd->512_batch->128_new_midi_embeddings\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "embedding = 512\n",
    "heads = 4\n",
    "layers = 4\n",
    "batch_size = 128\n",
    "learning_rate = 3e-5\n",
    "num_workers = 4\n",
    "midi_vocab = 128\n",
    "token_size = len(tokens)\n",
    "\n",
    "mconf = GPTConfig(token_size, block_size, midi_vocab, n_layer=layers, n_head=heads, n_embd=embedding)\n",
    "session_model = GPT(mconf)\n",
    "\n",
    "MODEL_NAME = \"../models/model_\"+ \"epochs->\" + str(epochs) + \"_heads->\" + str(heads) + \"_embd->\" + str(embedding) + \"_batch->\" + str(batch_size) + \"_new_midi_embeddings\"\n",
    "\n",
    "session_model = load_model(MODEL_NAME, session_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import formats as fmt\n",
    "import voicing as vc\n",
    "voicing = vc.Voicing()\n",
    "\n",
    "def generateSample(context, duration, style, tonality, session_model, dataset, split = True, temperature=1.0, sample=True, top_k=None, top_p=0.99):\n",
    "    if split: \n",
    "        data, _ = fmt.getArrayOfElementsInChord(context, duration)\n",
    "        print(data)\n",
    "        data = ['<style>'] + [style] + ['Tonality'] + [tonality] + ['<start>'] + ['|'] + data\n",
    "    else:\n",
    "        data = context\n",
    "    \n",
    "    midi, _ = voicing.get_midi(data)\n",
    "    # for d, m in zip(data, midi):\n",
    "    #     print(d, m)\n",
    "\n",
    "    i = 0\n",
    "    while ( i < 90):    \n",
    "        x = torch.tensor([dataset.stoi[s] for s in data], dtype=torch.long)[None,...].to('cuda')\n",
    "        m = torch.tensor(midi, dtype=torch.long)[None,...].to('cuda')\n",
    "        \n",
    "        #print(x.shape, m.shape)\n",
    "        y = sample_new(session_model, x, m, 1, temperature=temperature, sample=sample, top_k=top_k, top_p=top_p)[0]\n",
    "        \n",
    "        data = [dataset.itos[int(i)] for i in y if dataset.itos[int(i)]]\n",
    "        \n",
    "        if len(data) > 2:\n",
    "            if data[-1] == data[-2]:\n",
    "                print(\"Duplicated element: \", data[-1], data[-2])\n",
    "                data = data[:-1]\n",
    "                \n",
    "        if data[-2] == '.' and data[-1] not in voicing.durations:\n",
    "            print(\"Durations are not correct: \", data[-1], data[-2])\n",
    "            data = data[:-2]\n",
    "            \n",
    "        if data[-2] in voicing.durations and data[-1] not in voicing.all_notes:\n",
    "            print(\"Note is not correct: \", data[-1], data[-2])\n",
    "            data = data[:-2]\n",
    "            \n",
    "        #print(data)\n",
    "        midi, status = voicing.get_midi(data)\n",
    "        if status == False:\n",
    "            #erase the last element\n",
    "            print(\"Error creating the MIDI format\")\n",
    "            break\n",
    "        i+=1 \n",
    "\n",
    "    #myChords = convertChordsFromOutput(data)\n",
    "    #print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '4.0', 'C', 'maj7', '.', '4.0', 'D', 'm7', '.', '4.0', 'E', 'm7', 'add 9']\n",
      "\n",
      "<style> Jazz Tonality Bb major <start> | . 4.0 C maj7 . 4.0 D m7 . 4.0 E m7 add 9 | \n",
      ". 4.0 F m7 add 9 | . 2.0 E m7 add 9 . 2.0 D m7 add 9 | . 2.0 Ab \n",
      "m7 add 9 . 2.0 Db dom7 add 9 | . 2.0 D m7 add 9 . 2.0 G dom7 add b9 | . \n",
      "4.0 C maj7 | . 4.0 D dom7 add 9 | . 4.0 C maj7 | . 4.0 D dom7 add 9 \n",
      "| . 4.0 D dom7 add 9 Form_Coda | . 4.0 G dom7 alter #5 e|| :| |: . 4.0 C maj7 \n",
      "| . 4.0 D dom7 add 9 | . 4.0 \n",
      "-------------------------\n",
      "\n",
      "['Cmaj7', 'Dm7', 'Em7 add 9', 'Fm7 add 9', 'Em7 add 9', 'Dm7 add 9', 'Abm7 add 9', 'Db7 add 9', 'Dm7 add 9', 'G7 add b9', 'Cmaj7', 'D7 add 9', 'Cmaj7', 'D7 add 9', 'D7 add 9', 'G7 alter #5', 'Cmaj7', 'D7 add 9']\n"
     ]
    }
   ],
   "source": [
    "context = ['Cmaj7', 'Dm7', 'Em7 add 9']\n",
    "\n",
    "divide = True\n",
    "duration = np.full(len(context), 4.0, dtype=float)\n",
    "myStyle = 'Jazz'\n",
    "tonality = 'Bb major'\n",
    "data = generateSample(context, duration, myStyle, tonality, session_model, dataset, divide, temperature=1.1, sample=True, top_k=None, top_p=0.999)\n",
    "\n",
    "c = 0\n",
    "for e in data:\n",
    "    if c % 20 == 0: \n",
    "        print()\n",
    "    print(e, end=' ')\n",
    "    c+=1\n",
    "\n",
    "print('\\n-------------------------\\n')\n",
    "seq = voicing.convertChordsFromOutput(data)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song: 154433_13_9_2024_generated_Jazz.mid\n",
      "file: 154433_13_9_2024_generated_Jazz.txt\n",
      "MIDI file created! \n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(vc)\n",
    "voicing = vc.Voicing()\n",
    "\n",
    "myStyle = data[1]\n",
    "midi, _ = voicing.convert_chords_to_voicing(data)\n",
    "\n",
    "name = voicing.export_to_midi(midi, \"generated_\"+myStyle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv412\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv412_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv412\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAAAroA/wMAAOAAQM5gkDBAAJA7OgCQPkEAkEBOAJBDUIK7AIAwAACAOwAAgD4AAIBAAACAQwAAkDJPAJA5RwCQPE0AkEFPgrsAgDIAAIA5AACAPAAAgEEAAJA0TACQPkQAkEJQAJBDRoK7AIA0AACAPgAAgEIAAIBDAACQNVMAkD9HAJBDQwCQREyCuwCANQAAgD8AAIBDAACARAAAkDRAAJA+QQCQQjkAkENBgZ1AgDQAAIA+AACAQgAAgEMAAJAyRwCQOVIAkDxJAJBBRgCQQDqBnUCAMgAAgDkAAIA8AACAQQAAgEAAAJAsQQCQMzcAkDY8AJA7OwCQOkuBnUCALAAAgDMAAIA2AACAOwAAgDoAAJAxOQCQO1QAkD9OAJBBUQCQRECBnUCAMQAAgDsAAIA/AACAQQAAgEQAAJAyOQCQPFEAkEFLAJBFOgCQQEKBnUCAMgAAgDwAAIBBAACARQAAgEAAAJArRQCQNUsAkDs+AJA4R4GdQIArAACANQAAgDsAAIA4AACQMEoAkDs8AJA+TgCQQEuCuwCAMAAAgDsAAIA+AACAQAAAkDI5AJA8OgCQQkkAkEVIAJBAS4K7AIAyAACAPAAAgEIAAIBFAACAQAAAkDBAAJA7OgCQQEoAkENJgrsAgDAAAIA7AACAQAAAgEMAAJAyPACQPE0AkEA3AJBCQQCQRTiCuwCAMgAAgDwAAIBAAACAQgAAgEUAAJAyRQCQPDcAkEA6AJBCSgCQRTiCuwCAMgAAgDwAAIBAAACAQgAAgEUAAJArSgCQNTcAkDs8AJA/UoK7AIArAACANQAAgDsAAIA/AACQMEoAkDtBAJA+TgCQQEAAkENRgrsAgDAAAIA7AACAPgAAgEAAAIBDAACQMjwAkDxEAJBARACQQjiCuwCAMgAAgDwAAIBAAACAQgDOYP8vAA==\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv412_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv412_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import voicing as vc\n",
    "importlib.reload(vc)\n",
    "voicing = vc.Voicing()\n",
    "\n",
    "path = \"/workspace/data/midi_files/\"+name\n",
    "voicing.play_midi(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file generated:  154433_13_9_2024_detuned_Cmaj_chord.mid\n"
     ]
    }
   ],
   "source": [
    "voicing.MidiChord()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
