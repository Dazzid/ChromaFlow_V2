{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model import GPT, GPTConfig\n",
    "import torch\n",
    "from utils import *\n",
    "\n",
    "from mingpt_utils import set_seed\n",
    "from mingpt_utils import sample_new, sample\n",
    "import pytz\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.load('../data/formatted/tokens.npy', allow_pickle=True)\n",
    "train = np.load('../data/shuffled/dataset_train.npy', allow_pickle=True)\n",
    "midi_train = np.load('../data/shuffled/midi_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 43272 pieces, 195 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "block_size = 2048\n",
    "dataset = TokenDatasetMidi(train, midi_train, block_size, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/17/2024 16:55:29 - INFO - model -   number of parameters: 1.282714e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded ../models/model_epochs->90_heads->4_embd->512_batch->32_new_midi_embeddings\n"
     ]
    }
   ],
   "source": [
    "epochs = 90\n",
    "embedding = 512\n",
    "heads = 4\n",
    "layers = 4\n",
    "batch_size = 32\n",
    "learning_rate = 3e-5\n",
    "num_workers = 4\n",
    "midi_vocab = 128\n",
    "token_size = len(tokens)\n",
    "\n",
    "mconf = GPTConfig(token_size, block_size, midi_vocab, n_layer=layers, n_head=heads, n_embd=embedding)\n",
    "session_model = GPT(mconf)\n",
    "\n",
    "MODEL_NAME = \"../models/model_\"+ \"epochs->\" + str(epochs) + \"_heads->\" + str(heads) + \"_embd->\" + str(embedding) + \"_batch->\" + str(batch_size) + \"_new_midi_embeddings\"\n",
    "\n",
    "session_model = load_model(MODEL_NAME, session_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import formats as fmt\n",
    "import voicing as vc\n",
    "voicing = vc.Voicing()\n",
    "\n",
    "def generateSample(context, duration, style, tonality, session_model, dataset, temperature=1.0, sample=True, top_k=None, top_p=0.99):\n",
    "    data = fmt.getArrayOfElementsInChord(context, duration)\n",
    "    data = ['<style>'] + [style] + ['Tonality'] + [tonality] + ['<start>'] + ['|'] + data\n",
    "    print(data)\n",
    "    midi, _ = voicing.get_midi(data)\n",
    "    # for d, m in zip(data, midi):\n",
    "    #     print(d, m)\n",
    "\n",
    "    i = 0\n",
    "    while ( i < 500):    \n",
    "        x = torch.tensor([dataset.stoi[s] for s in data], dtype=torch.long)[None,...].to('cuda')\n",
    "        m = torch.tensor(midi, dtype=torch.long)[None,...].to('cuda')\n",
    "        \n",
    "        #print(x.shape, m.shape)\n",
    "        y = sample_new(session_model, x, m, 1, temperature=temperature, sample=sample, top_k=top_k, top_p=top_p)[0]\n",
    "        \n",
    "        data = [dataset.itos[int(i)] for i in y if dataset.itos[int(i)]]\n",
    "        \n",
    "        if len(data) > 2:\n",
    "            if data[-1] == data[-2]:\n",
    "                print(\"Duplicated element: \", data[-1], data[-2])\n",
    "                data = data[:-1]\n",
    "                \n",
    "        if data[-2] == '.' and data[-1] not in voicing.durations:\n",
    "            data = data[:-2]\n",
    "            \n",
    "        if data[-2] in voicing.durations and data[-1] not in voicing.all_notes:\n",
    "            data = data[:-2]\n",
    "            \n",
    "        #print(data)\n",
    "        midi, status = voicing.get_midi(data)\n",
    "        if status == False:\n",
    "            #erase the last element\n",
    "            print(\"Error creating the MIDI format\")\n",
    "            break\n",
    "        i+=1 \n",
    "\n",
    "    #myChords = convertChordsFromOutput(data)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<style>', 'Rock', 'Tonality', 'C major', '<start>', '|', '.', '4.0', 'D']\n",
      "['<style>', 'Rock', 'Tonality', 'C major', '<start>', '|', '.', '4.0', 'D', 'm7', '|', '.', '4.0', 'G', 'dom7', '|', '.', '4.0', 'C', 'maj7', '|', '.', '2.0', 'C', 'maj', '/', 'E', '|', '.', '4.0', 'D', 'm7', '|', '.', '4.0', 'Bb', 'maj7', '|', '.', '2.0', 'A', 'm7', '.']\n"
     ]
    }
   ],
   "source": [
    "context = ['D']\n",
    "duration = np.full(len(context), 4.0, dtype=float)\n",
    "myStyle = 'Rock'\n",
    "tonality = 'C major'\n",
    "data = generateSample(context, duration, myStyle, tonality, session_model, dataset, temperature=1.0, sample=True, top_k=None, top_p=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song: generated_2\n",
      "MIDI file created! \n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "midi, _ = voicing.convert_chords_to_voicing(data)\n",
    "voicing.export_to_midi(midi, \"generated_2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
