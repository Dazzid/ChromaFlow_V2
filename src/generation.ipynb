{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model import GPT, GPTConfig\n",
    "import torch\n",
    "from utils import *\n",
    "\n",
    "from mingpt_utils import set_seed\n",
    "from mingpt_utils import sample_new, sample\n",
    "import pytz\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.load('../data/formatted/tokens.npy', allow_pickle=True)\n",
    "train = np.load('../data/shuffled/dataset_train.npy', allow_pickle=True)\n",
    "midi_train = np.load('../data/shuffled/midi_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 43272 pieces, 195 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "block_size = 2048\n",
    "dataset = TokenDatasetMidi(train, midi_train, block_size, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/15/2024 12:53:57 - INFO - model -   number of parameters: 3.268096e+06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded /workspace/models/model_epochs->90_heads->4_embd->256_batch->32_new_midi_embeddings\n"
     ]
    }
   ],
   "source": [
    "epochs = 90\n",
    "embedding = 256\n",
    "heads = 4\n",
    "layers = 4\n",
    "batch_size = 32\n",
    "learning_rate = 3e-5\n",
    "num_workers = 4\n",
    "midi_vocab = 128\n",
    "token_size = len(tokens)\n",
    "\n",
    "mconf = GPTConfig(token_size, block_size, midi_vocab, n_layer=layers, n_head=heads, n_embd=embedding)\n",
    "session_model = GPT(mconf)\n",
    "\n",
    "MODEL_NAME = \"/workspace/models/model_epochs->90_heads->4_embd->256_batch->32_new_midi_embeddings\"\n",
    "session_model = load_model(MODEL_NAME, session_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import formats as fmt\n",
    "import voicing as vc\n",
    "voicing = vc.Voicing()\n",
    "\n",
    "def generateSample(context, duration, style, tonality, session_model, dataset, temperature=1.0, sample=True, top_k=None, top_p=0.99):\n",
    "    data = fmt.getArrayOfElementsInChord(context, duration)\n",
    "    data = ['<style>'] + [style] + ['Tonality'] + [tonality] + ['<start>'] + ['Form_A'] + ['|'] + data\n",
    "    print(data)\n",
    "    midi, _ = voicing.get_midi(data)\n",
    "    print(midi)\n",
    "\n",
    "    i = 0\n",
    "    while ( i < 100):    \n",
    "        x = torch.tensor([dataset.stoi[s] for s in data], dtype=torch.long)[None,...].to('cuda')\n",
    "        m = torch.tensor(midi, dtype=torch.long)[None,...].to('cuda')\n",
    "        \n",
    "        #print(x.shape, m.shape)\n",
    "        y = sample_new(session_model, x, m, 1, temperature=temperature, sample=sample, top_k=top_k, top_p=top_p)[0]\n",
    "        \n",
    "        data = [dataset.itos[int(i)] for i in y if dataset.itos[int(i)] != '<end>' and dataset.itos[int(i)] != '<pad>']\n",
    "        \n",
    "        if len(data) > 2:\n",
    "            if data[-1] == data[-2]:\n",
    "                print(\"Duplicated element: \", data[-1], data[-2])\n",
    "                data = data[:-1]\n",
    "                \n",
    "        #print(data)\n",
    "        midi, status = voicing.get_midi(data)\n",
    "        if status == False:\n",
    "            #erase the last element\n",
    "            print(\"Error creating the MIDI format\")\n",
    "            break\n",
    "        i+=1 \n",
    "\n",
    "    #myChords = convertChordsFromOutput(data)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<style>', 'Jazz', 'Tonality', 'D major', '<start>', 'Form_A', '|', '.', '4.0', 'D']\n",
      "[[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [50  0  0  0  0  0  0  0]]\n",
      "Duplicated element:  . .\n",
      "['<style>', 'Jazz', 'Tonality', 'D major', '<start>', 'Form_A', '|', '.', '4.0', 'D', 'maj7', '|', '.', '4.0', '/', 'G', '|', '.', '4.0', 'F#', 'm7', 'alter b5', '|', '.', '2.0', 'B', 'dom7', '|', '.', '2.0', 'E', 'dom7', '|', '.', '2.0', 'E', 'dom7', '|', '.', '4.0', '/', 'D', '|', '.', '2.0', 'C#', 'm7', '.', '2.0', 'Bbb', 'o7', '|', '.', '/', 'C#', '|', '.', '|', '.', '2.0', 'add 9', 'alter b5', '|', '.', '|', '.', 'add b6', '|', '.', '4.0', '|', '.', '/', 'A', '|', '.', '|', '.', '|', '.', '|', '.', '2.0', 'Ab', 'dom7', '|', '.', '4.0', 'alter b5', '|', '.', 'alter #5', '|', '.', '2.0', 'F#', 'm', '|', '.', 'add b6', '|', '.', '2.0', 'G#', 'sus7', 'add b9', '|', '.', '2.0']\n"
     ]
    }
   ],
   "source": [
    "context = ['D']\n",
    "duration = np.full(len(context), 4.0, dtype=float)\n",
    "myStyle = 'Jazz'\n",
    "tonality = 'D major'\n",
    "data = generateSample(context, duration, myStyle, tonality, session_model, dataset, temperature=1.0, sample=True, top_k=None, top_p=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
