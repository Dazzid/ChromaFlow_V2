{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56412, 1024, 2) (56412, 1024, 3) (56412,)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(\"../data/formatted/dataset.npy\", allow_pickle=True)\n",
    "midi_dataset = np.load(\"../data/formatted/midi_dataset.npy\", allow_pickle=True)\n",
    "meta_dataset = np.load(\"../data/formatted/meta_augmented.npy\", allow_pickle=True)\n",
    "\n",
    "print(dataset.shape, midi_dataset.shape, meta_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Style' 0.0]\n",
      " ['Medium Swing' 0.0]\n",
      " ['Tonality' 0.0]\n",
      " ...\n",
      " ['<pad>' 0.0]\n",
      " ['<pad>' 0.0]\n",
      " ['<pad>' 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check both dataset are equivalent \n",
    "x, y = dataset.shape[0], dataset.shape[1]\n",
    "\n",
    "for i in range (x):\n",
    "    for j in range (y):\n",
    "        element = dataset[i][j][0]\n",
    "        check = midi_dataset[i][j][2] \n",
    "        if element != check:\n",
    "            print(\"Error at \", i, j)\n",
    "            print(element, check)\n",
    "            break   \n",
    "        \n",
    "print(\"Dataset are equivalent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n",
      "{'o', ':|', 'Moderately', 'Medium Up Swing', 'Traditional Gospel', 'Chacarera', 'Medium Rock', 'C', 'Jazz', 'Cuban Son', 'Folk', 'Blues Rock', '<Start>', 'add b9', 'Funk Jazz', 'B major', 'Db minor', \"R'n'B\", 'Medium Blues', 'E##', 'Slow Ballad', 'dom7', 'Db', 'Rock/Reggae', 'A minor', 'D', 'Afro', 'Form_C', 'Rock/Hip Hop', 'add 9', 'Medium Swing', 'aug', 'Rock Blues', 'Moderate Latin', 'Shuffle Blues', 'Bbb', 'Gypsy Swing', 'Up Swing', 'B##', 'UP Swing', 'Afoxé-Samba', 'D##', 'Soul', 'o_maj7', 'alter b5', 'Up Tempo Swing', 'Samba-Rock', 'Waltz', 'Afoxe', 'add 2', 'D#', 'Choro - Samba', 'Form_A', 'Up Samba', 'Rock Slow', 'Up Waltz (One Feel)', 'March', 'Slow Swing', 'maj6', 'Blues Pop', 'Salsa', 'add 11', 'Bossa Nova', 'add #5', 'D major', 'E#', 'add b13', 'Pop Shuffle', 'Electric Blues', 'Blues', 'm6', 'Bossa Acoustic', 'Gb minor', 'Electro Pop', 'Fb', 'sus4', 'm7', '<End>', 'Gypsy Bossa', 'Samba Funk', 'Rock-Folk', 'Medium Slow', 'Medium Waltz', 'alter #11', 'Form_D', 'Abb', 'Deliberately', 'Latin-Swing', 'Worship', 'C##', '|', 'add #11', 'add #7', 'Pop-Shuffle', 'Repeat_2', 'G major', 'Even 8ths', 'Ab', \"Even 8's\", 'Reggae Pop', 'F#', 'A##', 'Country Ballad', 'G minor', 'Medium Country', 'E major', 'Rock Pop', 'Cbb', 'RnB', 'Ballad', 'E', 'Form_Coda', 'C#', 'Son', 'G##', 'Bolero-Son', 'Tonality', 'Form_Segno', 'add b6', 'Repeat_3', 'A', 'Tango', 'Forró', 'Ab minor', 'Gb', 'm', 'Gypsy Waltz', 'Form_intro', 'Repeat_0', 'G#', 'Folk-Rock', 'power', 'add 7', 'Gbb', 'Disco', 'C minor', 'Afoxé', 'A#', 'Reggae', '.', 'alter b9', 'Medium Up', 'alter #5', 'Bb major', 'Fast Blues', 'Bolero-Cha', 'Folk Ballad', 'Gb major', 'A major', 'G', 'F', 'Slow Blues', 'add #9', 'Cb', 'Montuno', 'Medium Shuffle', 'Slow Shuffle', 'Mambo', 'Frevo', 'Eb minor', 'Bb minor', 'Blues Shuffle', 'B#', 'F major', 'Samba Enredo', \"Rock'n'Roll\", 'Db major', 'Dreamlike', 'Baião', '128 Feel', 'Beatles', 'maj', 'Cha Cha', 'Hymn', 'Dbb', 'Medium Funk', 'Fbb', 'Funk Rock', 'Bright Shuffle Blues', 'F##', 'add 13', 'Form_verse', 'Slow Bossa', 'Even 16ths', 'Form_B', 'Calypso', 'Pop Ballad', '/', 'Folk Rock', 'o7', 'Funk', \"Even 8th's\", 'Merengue', 'Style', 'Up Tempo', '<pad>', 'Maxixe', 'Samba', 'Pop', 'Ab major', 'sus7', 'Afro-Samba', 'Foxtrot', 'E minor', 'Bb', 'Ebb', 'Slowly', 'Pop jazz', 'major-13th', 'Musical', 'Pop Folk', 'Country Blues', 'Eb major', 'Latin', 'Rock', 'Soul Ballad', 'N.C.', 'Fusion', 'Medium Pop', 'Repeat_1', 'Samba-Funk', 'Shuffle', 'maj7', 'Samba Reggae', 'Medium Ballad', 'Choro', 'B', 'Rock Ballad', 'Bolero', 'Pop Rock', 'F minor', 'C major', 'Med Up Latin', 'Marchinha', 'B minor', 'Slow Rock', 'alter #9', 'Power Ballad', 'Disco Funk', 'D minor', 'Gary Aprile', 'Eb', 'Fast Swing'}\n"
     ]
    }
   ],
   "source": [
    "#Token from dataset\n",
    "\n",
    "chords_array = [[item[0] for item in row] for row in dataset]\n",
    "concatenated_array = np.hstack(chords_array) \n",
    "tokens = set(concatenated_array)\n",
    "\n",
    "print(len(tokens))\n",
    "print(tokens)\n",
    "np.save(\"../data/formatted/tokens.npy\", list(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o': 0, ':|': 1, 'Moderately': 2, 'Medium Up Swing': 3, 'Traditional Gospel': 4, 'Chacarera': 5, 'Medium Rock': 6, 'C': 7, 'Jazz': 8, 'Cuban Son': 9, 'Folk': 10, 'Blues Rock': 11, '<Start>': 12, 'add b9': 13, 'Funk Jazz': 14, 'B major': 15, 'Db minor': 16, \"R'n'B\": 17, 'E##': 18, 'Medium Blues': 19, 'Slow Ballad': 20, 'dom7': 21, 'Db': 22, 'Rock/Reggae': 23, 'A minor': 24, 'D': 25, 'Afro': 26, 'Form_C': 27, 'Rock/Hip Hop': 28, 'add 9': 29, 'Medium Swing': 30, 'aug': 31, 'Rock Blues': 32, 'Moderate Latin': 33, 'Shuffle Blues': 34, 'Bbb': 35, 'Gypsy Swing': 36, 'B##': 37, 'Up Swing': 38, 'Fast Swing': 39, 'UP Swing': 40, 'Afoxé-Samba': 41, 'Gospel Ballad': 42, 'D##': 43, 'Soul': 44, 'o_maj7': 45, 'alter b5': 46, 'Up Tempo Swing': 47, 'Samba-Rock': 48, 'Waltz': 49, 'Afoxe': 50, 'add 2': 51, 'D#': 52, 'Choro - Samba': 53, 'Form_A': 54, 'Up Samba': 55, 'Rock Slow': 56, 'Up Waltz (One Feel)': 57, 'March': 58, 'Slow Swing': 59, 'maj6': 60, 'Blues Pop': 61, 'Rock Waltz': 62, 'add 11': 63, 'Bossa Nova': 64, 'Salsa': 65, 'add #5': 66, 'D major': 67, 'E#': 68, 'add b13': 69, 'Electric Blues': 70, 'Pop Shuffle': 71, 'Blues': 72, 'm6': 73, 'Bossa Acoustic': 74, 'Gb minor': 75, 'Electro Pop': 76, 'Fb': 77, 'sus4': 78, 'm7': 79, '<End>': 80, 'Gypsy Bossa': 81, 'Samba Funk': 82, 'Rock-Folk': 83, 'Medium Slow': 84, 'Medium Waltz': 85, 'alter #11': 86, 'Form_D': 87, 'Abb': 88, 'Deliberately': 89, 'Latin-Swing': 90, 'Worship': 91, 'C##': 92, '|': 93, 'add #11': 94, 'add #7': 95, 'Pop-Shuffle': 96, 'Repeat_2': 97, 'G major': 98, 'Even 8ths': 99, 'Ab': 100, \"Even 8's\": 101, 'Reggae Pop': 102, 'F#': 103, 'A##': 104, 'Country Ballad': 105, 'G minor': 106, 'Medium Country': 107, 'E major': 108, 'Rock Pop': 109, 'Cbb': 110, 'RnB': 111, 'Ballad': 112, 'E': 113, 'Form_Coda': 114, 'C#': 115, 'Son': 116, 'G##': 117, 'Bolero-Son': 118, 'Tonality': 119, 'Form_Segno': 120, 'Tango': 121, 'Repeat_3': 122, 'A': 123, 'add b6': 124, 'Forró': 125, 'Ab minor': 126, 'Gb': 127, 'm': 128, 'Gypsy Waltz': 129, 'Form_intro': 130, 'Repeat_0': 131, 'G#': 132, 'Folk-Rock': 133, 'power': 134, 'add 7': 135, 'Gbb': 136, 'Disco': 137, 'C minor': 138, 'Afoxé': 139, 'A#': 140, 'Reggae': 141, '.': 142, 'alter b9': 143, 'Medium Up': 144, 'alter #5': 145, 'Bb major': 146, 'Fast Blues': 147, 'Bolero-Cha': 148, 'Folk Ballad': 149, 'Gb major': 150, 'A major': 151, 'G': 152, 'F': 153, 'Dreamlike': 154, 'Slow Blues': 155, 'Cb': 156, 'add #9': 157, 'Montuno': 158, 'Medium Shuffle': 159, 'Slow Shuffle': 160, 'Mambo': 161, 'Frevo': 162, 'Eb minor': 163, 'Bb minor': 164, 'Blues Shuffle': 165, 'B#': 166, 'F major': 167, 'Samba Enredo': 168, 'Beatles': 169, 'Db major': 170, \"Rock'n'Roll\": 171, 'Baião': 172, '128 Feel': 173, 'maj': 174, 'Hymn': 175, 'Cha Cha': 176, 'Dbb': 177, 'Medium Funk': 178, 'Fbb': 179, 'Funk Rock': 180, 'Bright Shuffle Blues': 181, 'F##': 182, 'add 13': 183, 'Form_verse': 184, 'Slow Bossa': 185, 'Even 16ths': 186, 'Form_B': 187, 'Calypso': 188, 'Pop Ballad': 189, '/': 190, 'Folk Rock': 191, 'Funk': 192, 'o7': 193, \"Even 8th's\": 194, 'Merengue': 195, 'Style': 196, 'Up Tempo': 197, '<pad>': 198, 'Maxixe': 199, 'Samba': 200, 'Pop': 201, 'Ab major': 202, 'sus7': 203, 'Afro-Samba': 204, 'Foxtrot': 205, 'E minor': 206, 'Bb': 207, 'Ebb': 208, 'Slowly': 209, 'Pop jazz': 210, 'major-13th': 211, 'Musical': 212, 'Pop Folk': 213, 'Eb major': 214, 'Latin': 215, 'Rock': 216, 'Soul Ballad': 217, 'N.C.': 218, 'Fusion': 219, 'Medium Pop': 220, 'Repeat_1': 221, 'Samba-Funk': 222, 'Shuffle': 223, 'maj7': 224, 'Samba Reggae': 225, 'Medium Ballad': 226, 'Choro': 227, 'B': 228, 'Rock Ballad': 229, 'Bolero': 230, 'Pop Rock': 231, 'F minor': 232, 'C major': 233, 'Med Up Latin': 234, 'Marchinha': 235, 'B minor': 236, 'Slow Rock': 237, 'alter #9': 238, 'Power Ballad': 239, 'Disco Funk': 240, 'D minor': 241, 'Gary Aprile': 242, 'Eb': 243, 'Country Blues': 244}\n"
     ]
    }
   ],
   "source": [
    "stoi = { tk:i for i,tk in enumerate(tokens) }\n",
    "itos = { i:tk for i,tk in enumerate(tokens) }\n",
    "\n",
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Get the number of real songs\n",
    "realSongs = len(dataset)/12\n",
    "tenPercent = int(0.1 * realSongs)\n",
    "\n",
    "#random a number without repeating number\n",
    "randomList = random.sample(range(0, int(realSongs)), tenPercent)\n",
    "\n",
    "#if number is bigger than 12 multiply it by 12\n",
    "for i in range(len(randomList)):\n",
    "    randomList[i] = randomList[i] * 12\n",
    "\n",
    "#populate a random list with the 12 subsequent numbers per value\n",
    "final_random_list=[]\n",
    "for number in randomList:\n",
    "    for i in range(12):\n",
    "        final_random_list.append(number+i)\n",
    "\n",
    "#check if a number is duplicated \n",
    "print(len(final_random_list) == len(set(final_random_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the random list\n",
    "np.save('../data/formatted/final_random_list.npy', final_random_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset and validation using the random list\n",
    "dataset_test = dataset[final_random_list]\n",
    "midi_test = midi_dataset[final_random_list]\n",
    "meta_test = meta_dataset[final_random_list]\n",
    "\n",
    "dataset_train = np.delete(dataset, final_random_list, axis=0)\n",
    "midi_train = np.delete(midi_dataset, final_random_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the train and test dataset\n",
    "#test\n",
    "np.save('../data/formatted/dataset_test.npy', dataset_test)\n",
    "np.save('../data/formatted/midi_test.npy', midi_test)\n",
    "np.save('../data/formatted/meta_test.npy', meta_test)\n",
    "#train\n",
    "np.save('../data/formatted/dataset_train.npy', dataset_train)\n",
    "np.save('../data/formatted/midi_train.npy', midi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#create a file with shuffled reference index\n",
    "def createWindowedShuffleReference(type, size, window, save = False):\n",
    "    s = np.arange(0, size, 1)\n",
    "    #num = np.arange(0, len(data)/10, 1)\n",
    "    np.random.shuffle(s)\n",
    "\n",
    "    n = int(size/window)\n",
    "    numlist = random.sample(range(n), n)\n",
    "    numlist = np.array(numlist)\n",
    "    numlist = numlist * window\n",
    "\n",
    "    m = np.max(numlist)\n",
    "    l_ref = size-window\n",
    "    print('real:', size, 'max:', m, 'length_ref:',l_ref)\n",
    "\n",
    "    if m != l_ref:\n",
    "        rest = m - l_ref\n",
    "        numlist = numlist - rest\n",
    "\n",
    "    ref = []\n",
    "    for num in numlist:\n",
    "        if num == 0:\n",
    "            print(\"OK\")\n",
    "        for i in range(0,window):\n",
    "            ref.append(num+i)\n",
    "\n",
    "    #return the shuffled list\n",
    "    if save:\n",
    "        np.savetxt(\"../data/shuffle_\" + type + \".txt\", ref, fmt='%i', delimiter=\" \", header='Array shape: ('+str(size)+', 1)')\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(folder, name):\n",
    "    data_path = folder + '/' + name\n",
    "    data = np.loadtxt(data_path)\n",
    "    f = open(data_path, \"r\")\n",
    "    format = f.readline().replace('# Array shape: (', '').replace('\\n', '').replace(')', '')\n",
    "    format = np.array(format.split(', ')).astype(int)\n",
    "    f.close()\n",
    "    return data, format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50772, 1024, 2) (50772, 1024, 3) (5640, 1024, 2) (5640, 1024, 3)\n",
      "real: 50772 max: 50771 length_ref: 50771\n",
      "OK\n",
      "real: 5640 max: 5639 length_ref: 5639\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "train_dataset = np.load('../data/formatted/dataset_train.npy', allow_pickle=True)\n",
    "test_dataset = np.load('../data/formatted/dataset_test.npy', allow_pickle=True)\n",
    "\n",
    "train_midi = np.load('../data/formatted/midi_train.npy', allow_pickle=True)\n",
    "test_midi = np.load('../data/formatted/midi_test.npy', allow_pickle=True)\n",
    "\n",
    "print(train_dataset.shape, train_midi.shape, test_dataset.shape, test_midi.shape)\n",
    "\n",
    "BATCH_SHUFFLE_SIZE = 1\n",
    "ref = createWindowedShuffleReference(\"train\", len(train_dataset), BATCH_SHUFFLE_SIZE, True)\n",
    "ref_test = createWindowedShuffleReference(\"test\", len(test_dataset), BATCH_SHUFFLE_SIZE, True)\n",
    "\n",
    "# first shuffle the train dataset\n",
    "shuffle_train, format_train = getData('../data', 'shuffle_train.txt')\n",
    "shuffle_train = shuffle_train.reshape(format_train[0], ).astype(int)\n",
    "shuffle_train = shuffle_train.tolist()\n",
    "dataset = train_dataset[shuffle_train]\n",
    "midiDataset = train_midi[shuffle_train]\n",
    "\n",
    "#second shuffle the test dataset\n",
    "shuffle_test, format_test = getData('../data', 'shuffle_test.txt')\n",
    "shuffle_test = shuffle_test.reshape(format_test[0], ).astype(int)\n",
    "shuffle_test = shuffle_test.tolist()\n",
    "validation = test_dataset[shuffle_test]\n",
    "midi_validation = test_midi[shuffle_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/shuffled/dataset_train.npy', dataset)\n",
    "np.save('../data/shuffled/midi_train.npy', midiDataset)\n",
    "np.save('../data/shuffled/dataset_test.npy', validation)\n",
    "np.save('../data/shuffled/midi_test.npy', midi_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n",
    "\n",
    "max_length = 1024\n",
    "id = 0\n",
    "tokens = np.load('../data/formatted/tokens.npy', allow_pickle=True)\n",
    "train = np.load('../data/shuffled/dataset_train.npy', allow_pickle=True)\n",
    "test = np.load('../data/shuffled/dataset_test.npy', allow_pickle=True)\n",
    "midi_train = np.load('../data/shuffled/midi_train.npy', allow_pickle=True)\n",
    "midi_test = np.load('../data/shuffled/midi_test.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50772, 1024, 2) (5640, 1024, 2) (50772, 1024, 8) (5640, 1024, 8)\n",
      "data has 50772 pieces, 243 unique tokens.\n",
      "data has 5640 pieces, 243 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#extract the first dimension of MIDI dataset, to get shape (n, 1024, 1)\n",
    "\n",
    "midi_data_train = np.array([[chord[0] for chord in song] for song in midi_train])\n",
    "midi_data_test = np.array([[chord[0] for chord in song] for song in midi_test])\n",
    "  \n",
    "print(train.shape, test.shape, midi_data_train.shape, midi_data_test.shape)\n",
    "\n",
    "dataset = TokenDatasetMidi(train, midi_data_train,  max_length, tokens)\n",
    "validation = TokenDatasetMidi(test, midi_data_test, max_length, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9ceacac99d4ab28d4687f6376b070f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112527378524343, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/src/wandb/run-20240310_162506-g9fpobbz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/music_gpt/music_gpt_new_voicing/runs/g9fpobbz' target=\"_blank\">dashing-bird-1</a></strong> to <a href='https://wandb.ai/music_gpt/music_gpt_new_voicing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/music_gpt/music_gpt_new_voicing' target=\"_blank\">https://wandb.ai/music_gpt/music_gpt_new_voicing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/music_gpt/music_gpt_new_voicing/runs/g9fpobbz' target=\"_blank\">https://wandb.ai/music_gpt/music_gpt_new_voicing/runs/g9fpobbz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/music_gpt/music_gpt_new_voicing/runs/g9fpobbz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd87e7dcac0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "#wandb.login()\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"music_gpt_new_voicing\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"architecture\": \"Transformer - minGPT\",\n",
    "    \"dataset\": \"chords from iRealPro\",\n",
    "    \"epochs\": 250,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:  2\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from trainer import Trainer, TrainerConfig\n",
    "from mingpt_utils import set_seed\n",
    "from model import GPT, GPTConfig\n",
    "import torch\n",
    "print(\"Available devices: \", torch.cuda.device_count())\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from mingpt_utils import sample\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "embedding = 192\n",
    "heads = 4\n",
    "layers = 4\n",
    "batch_size = 64\n",
    "learning_rate = 3e-5\n",
    "num_workers = 4\n",
    "midi_vocab = 128\n",
    "\n",
    "mconf = GPTConfig(len(tokens), dataset.block_size, midi_vocab, n_layer=layers, n_head=heads, n_embd=embedding)\n",
    "session_model = GPT(mconf)\n",
    "MODEL_NAME = \"../models/model_\"+ \"epochs->\" + str(epochs) + \"_heads->\" + str(heads) + \"_embd->\" + str(embedding) + \"_batch->\" + str(batch_size) + \"_new_midi_embeddings\"\n",
    "print(MODEL_NAME)\n",
    "\n",
    "session_model = load_model(MODEL_NAME, session_model)\n",
    "\n",
    "if (session_model == None):\n",
    "    #mconf = GPTConfig(len(tokens), dataset.block_size, n_layer=layers, n_head=heads, n_embd=embbedings)\n",
    "    session_model = GPT(mconf)\n",
    "    tconf = TrainerConfig(max_epochs=epochs, \n",
    "                          batch_size=batch_size, \n",
    "                          learning_rate=learning_rate, \n",
    "                          num_workers=num_workers\n",
    "                          )\n",
    "    writer = SummaryWriter(log_dir='../runs/'+'logs') \n",
    "    trainer = Trainer(session_model, dataset, validation, tconf, writer)\n",
    "    trainer.train()\n",
    "    save_model(MODEL_NAME, session_model)\n",
    "    # [optional] finish the wandb run, necessary in notebooks\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
